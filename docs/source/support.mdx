# Help & Support 

We have a variety of Inference Endpoints blog posts to help you at https://huggingface.co/blog:

* [Getting Started with Hugging Face Inference Endpoints](https://huggingface.co/blog/inference-endpoints)
* [Why weâ€™re switching to Hugging Face Inference Endpoints, and maybe you should too](https://huggingface.co/blog/mantis-case-study)
* [Deploy LLMs with Hugging Face Inference Endpoints](https://huggingface.co/blog/inference-endpoints-llm)
* [ðŸ¤— LLM suggestions in Argilla with HuggingFace Inference Endpoints](https://huggingface.co/blog/alvarobartt/argilla-suggestions-via-inference-endpoints)
* [Deploy MusicGen in no time with Inference Endpoints](https://huggingface.co/blog/run-musicgen-as-an-api)
* New! [TGI Multi-LoRA: Deploy Once, Serve 30 models](https://huggingface.co/blog/multi-lora-serving)
* New! [Llama 3.1 - 405B, 70B & 8B with multilinguality and long context](https://huggingface.co/blog/llama31#hugging-face-inference-endpoints)

Need more help?

Feel free to ask questions on the forum so the community can also benefit from the answers:Â https://discuss.huggingface.co/. If you have any other questions or issues, please contact us at <api-enterprise@huggingface.co>. 

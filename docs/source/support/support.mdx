# Help & Support 

We have a variety of Inference Endpoints blog posts to help you at https://huggingface.co/blog:

* [Getting Started with Hugging Face Inference Endpoints](https://huggingface.co/blog/inference-endpoints)
* [Why we're switching to Hugging Face Inference Endpoints, and maybe you should too](https://huggingface.co/blog/mantis-case-study)
* [Deploy LLMs with Hugging Face Inference Endpoints](https://huggingface.co/blog/inference-endpoints-llm)
* [ðŸ¤— LLM suggestions in Argilla with HuggingFace Inference Endpoints](https://huggingface.co/blog/alvarobartt/argilla-suggestions-via-inference-endpoints)
* [Deploy MusicGen in no time with Inference Endpoints](https://huggingface.co/blog/run-musicgen-as-an-api)
* [Programmatically manage Inference Endpoints](https://www.philschmid.de/inference-endpoints-iac)
* [TGI Multi-LoRA: Deploy Once, Serve 30 models](https://huggingface.co/blog/multi-lora-serving)
* [Deploy open LLMs with vLLM on Inference Endpoints](https://www.philschmid.de/vllm-inference-endpoints)
* [Llama 3.1 - 405B, 70B & 8B with multilinguality and long context](https://huggingface.co/blog/llama31#hugging-face-inference-endpoints)
* NEW! [Investing in Performance: Fine-tune small models with LLM insights - a CFM case study](https://huggingface.co/blog/cfm-case-study)


Need more help?

Feel free to ask questions on the forum so the community can also benefit from the answers: https://discuss.huggingface.co/. If you have any other questions or issues, please contact us at <api-enterprise@huggingface.co>. 
